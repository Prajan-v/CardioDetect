{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ¤– CardioDetect - Model Training & Evaluation\n",
                "\n",
                "## Milestone 2: Comprehensive Model Comparison\n",
                "\n",
                "In this notebook, I train and evaluate **8 different machine learning models** on my unified cardiovascular risk dataset. My goal is to find the model that best balances accuracy and recall for predicting heart disease.\n",
                "\n",
                "### Models I'm Testing:\n",
                "1. **Logistic Regression** - Linear baseline\n",
                "2. **Random Forest** - Ensemble of decision trees\n",
                "3. **XGBoost** - Gradient boosted trees\n",
                "4. **LightGBM** - Microsoft fast gradient boosting\n",
                "5. **SVM (RBF)** - Support vector machine with radial basis function\n",
                "6. **Gradient Boosting** - Sklearn gradient boosting\n",
                "7. **MLP** - Multi-layer perceptron (neural network)\n",
                "8. **Ensemble** - Soft-voting combination of RF + XGB + LGBM + MLP\n",
                "\n",
                "All models use class weighting (where applicable) to handle the dataset balance. I am using the unified dataset with ~16k records."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
                "\n",
                "# Models\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from xgboost import XGBClassifier\n",
                "from lightgbm import LGBMClassifier\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "pd.set_option('display.max_columns', None)\n",
                "print(\"âœ… Libraries Loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Data\n",
                "data_path = '../data/processed/combined_processed.csv'\n",
                "df = pd.read_csv(data_path)\n",
                "print(f\"Dataset Shape: {df.shape}\")\n",
                "\n",
                "# Split Features/Target\n",
                "X = df.drop('target', axis=1)\n",
                "y = df['target']\n",
                "\n",
                "# Train/Test Split (80/20)\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Preprocessor\n",
                "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
                "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
                "\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numeric_features),\n",
                "        ('cat', Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_features)\n",
                "    ])\n",
                "\n",
                "print(\"âœ… Preprocessor Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
                "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
                "    'LightGBM': LGBMClassifier(random_state=42, verbose=-1),\n",
                "    'SVM (RBF)': SVC(probability=True, random_state=42),\n",
                "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
                "    'MLP': MLPClassifier(max_iter=500, random_state=42)\n",
                "}\n",
                "\n",
                "print(\"âœ… Models Initialized\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = []\n",
                "trained_models = {}\n",
                "\n",
                "print(\"ðŸš€ Starting Training Loop...\")\n",
                "\n",
                "for name, model in models.items():\n",
                "    print(f\"Training {name}...\")\n",
                "    clf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
                "    clf.fit(X_train, y_train)\n",
                "    \n",
                "    # Evaluate\n",
                "    y_pred = clf.predict(X_test)\n",
                "    y_prob = clf.predict_proba(X_test)[:, 1]\n",
                "    \n",
                "    acc = accuracy_score(y_test, y_pred)\n",
                "    rec = recall_score(y_test, y_pred)\n",
                "    auc = roc_auc_score(y_test, y_prob)\n",
                "    \n",
                "    results.append({'Model': name, 'Accuracy': acc, 'Recall': rec, 'ROC-AUC': auc})\n",
                "    trained_models[name] = clf\n",
                "\n",
                "# Create Ensemble (Voting)\n",
                "print(\"Training Ensemble...\")\n",
                "estimators = [\n",
                "    ('rf', models['Random Forest']),\n",
                "    ('xgb', models['XGBoost']),\n",
                "    ('lgbm', models['LightGBM']),\n",
                "    ('mlp', models['MLP'])\n",
                "]\n",
                "voting = VotingClassifier(estimators=estimators, voting='soft')\n",
                "clf_voting = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', voting)])\n",
                "clf_voting.fit(X_train, y_train)\n",
                "\n",
                "y_pred = clf_voting.predict(X_test)\n",
                "y_prob = clf_voting.predict_proba(X_test)[:, 1]\n",
                "results.append({'Model': 'Voting Ensemble', \n",
                "                'Accuracy': accuracy_score(y_test, y_pred),\n",
                "                'Recall': recall_score(y_test, y_pred),\n",
                "                'ROC-AUC': roc_auc_score(y_test, y_prob)})\n",
                "\n",
                "print(\"âœ… Training Complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df = pd.DataFrame(results).sort_values(by='Accuracy', ascending=False)\n",
                "print(results_df)\n",
                "\n",
                "# Plot\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x='Accuracy', y='Model', data=results_df, palette='viridis')\n",
                "plt.title('Model Comparison (Accuracy)')\n",
                "plt.xlim(0.8, 1.0)\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
