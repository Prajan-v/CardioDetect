{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CardioDetect – Systematic MLP Grid Search & Threshold Tuning\n",
    "\n",
    "**Objective**: Explore MLP architectures to beat `mlp_v2_best` (Acc=0.9359, Recall=0.9190) while maintaining recall ≥ 0.9190.\n",
    "\n",
    "**Grid**: 5 architectures × 4 alphas × 2 learning rates × 2 max_iters = 80 experiments\n",
    "\n",
    "**Output (this notebook)**: structured CSV with metrics for all experiments.\n",
    "\n",
    "**Note**: Obsidian notes and leaderboards are generated by a separate script (no Obsidian writes from this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n",
      "Results will be saved to: /Users/prajanv/CardioDetect/output/mlp_experiments\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, precision_score, \n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "from src.mlp_tuning import load_splits, encode_categorical_features\n",
    "\n",
    "# Where to store raw experiment results (CSV only, no Obsidian coupling)\n",
    "RESULTS_DIR = Path.cwd().parent / 'output' / 'mlp_experiments'\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Imports OK')\n",
    "print(f'Results will be saved to: {RESULTS_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 11286 | Val: 2418 | Test: 2419\n",
      "Features: 179\n"
     ]
    }
   ],
   "source": [
    "# Load data and scale features\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_splits()\n",
    "X_train, X_val, X_test = encode_categorical_features(X_train, X_val, X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s = scaler.transform(X_val)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "print(f'Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}')\n",
    "print(f'Features: {X_train_s.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiments to run: 80\n",
      "Baseline: Acc=0.9359, Recall=0.919\n",
      "Constraint: Recall >= 0.919\n"
     ]
    }
   ],
   "source": [
    "# ============ CONFIGURATION ============\n",
    "BASELINE_TEST_ACC = 0.9359\n",
    "BASELINE_TEST_RECALL = 0.9190\n",
    "RECALL_CONSTRAINT = 0.9190  # Hard constraint\n",
    "\n",
    "# Hyperparameter search space\n",
    "HIDDEN_LAYER_SIZES = [\n",
    "    (128, 64, 32),\n",
    "    (256, 128, 64),\n",
    "    (256, 256, 128),\n",
    "    (128, 64),\n",
    "    (64, 32),\n",
    "]\n",
    "ALPHAS = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "LEARNING_RATES = [0.001, 0.0007]\n",
    "MAX_ITERS = [300, 500]\n",
    "\n",
    "# Calculate total experiments\n",
    "total_experiments = len(HIDDEN_LAYER_SIZES) * len(ALPHAS) * len(LEARNING_RATES) * len(MAX_ITERS)\n",
    "print(f'Total experiments to run: {total_experiments}')\n",
    "print(f'Baseline: Acc={BASELINE_TEST_ACC}, Recall={BASELINE_TEST_RECALL}')\n",
    "print(f'Constraint: Recall >= {RECALL_CONSTRAINT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# ============ HELPER FUNCTIONS ============\n",
    "\n",
    "def compute_metrics(y_true, y_pred, y_proba):\n",
    "    \"\"\"Compute all metrics for a split.\"\"\"\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_true, y_proba),\n",
    "    }\n",
    "\n",
    "def eval_model_at_threshold(model, X, y, threshold=0.5):\n",
    "    \"\"\"Evaluate model at a specific threshold.\"\"\"\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    return compute_metrics(y, y_pred, y_proba)\n",
    "\n",
    "def find_best_threshold(model, X_val, y_val, recall_floor=0.9190):\n",
    "    \"\"\"\n",
    "    Find threshold that maximizes validation accuracy while maintaining recall >= recall_floor.\n",
    "    Returns (best_threshold, best_metrics_at_threshold).\n",
    "    \"\"\"\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    best_thresh = 0.5\n",
    "    best_acc = -1.0\n",
    "    best_rec = 0.0\n",
    "    \n",
    "    for thresh in np.linspace(0.1, 0.9, 81):\n",
    "        y_pred = (y_proba >= thresh).astype(int)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        \n",
    "        if rec >= recall_floor:\n",
    "            if acc > best_acc or (acc == best_acc and rec > best_rec):\n",
    "                best_acc = acc\n",
    "                best_rec = rec\n",
    "                best_thresh = thresh\n",
    "    \n",
    "    # If no threshold meets constraint, return default 0.5\n",
    "    if best_acc < 0:\n",
    "        best_thresh = 0.5\n",
    "    \n",
    "    # Compute full metrics at best threshold\n",
    "    y_pred = (y_proba >= best_thresh).astype(int)\n",
    "    metrics = compute_metrics(y_val, y_pred, y_proba)\n",
    "    \n",
    "    return best_thresh, metrics\n",
    "\n",
    "def get_confusion_matrix_str(y_true, y_pred):\n",
    "    \"\"\"Return confusion matrix as formatted string.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    return f'TP={tp}, FP={fp}, TN={tn}, FN={fn}'\n",
    "\n",
    "print('Helper functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895a1162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result row builder defined\n"
     ]
    }
   ],
   "source": [
    "# ============ RESULT ROW BUILDER ============\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def build_result_row(\n",
    "    exp_id,\n",
    "    config,\n",
    "    train_default,\n",
    "    val_default,\n",
    "    test_default,\n",
    "    best_thresh,\n",
    "    val_tuned,\n",
    "    test_tuned,\n",
    "    val_cm,\n",
    "    test_cm,\n",
    "    train_time,\n",
    "    early_stop_epoch,\n",
    "    converged,\n",
    "):\n",
    "    \"\"\"Build a single result row for the experiments CSV.\"\"\"\n",
    "    tn_val, fp_val, fn_val, tp_val = val_cm.ravel()\n",
    "    tn_test, fp_test, fn_test, tp_test = test_cm.ravel()\n",
    "\n",
    "    constraint_met = (val_tuned[\"recall\"] >= RECALL_CONSTRAINT) and (\n",
    "        test_tuned[\"recall\"] >= RECALL_CONSTRAINT\n",
    "    )\n",
    "    is_leader = constraint_met and (test_tuned[\"accuracy\"] > BASELINE_TEST_ACC)\n",
    "\n",
    "    return {\n",
    "        \"id\": exp_id,\n",
    "        \"hidden_layer_sizes\": str(config[\"hidden_layer_sizes\"]),\n",
    "        \"alpha\": config[\"alpha\"],\n",
    "        \"learning_rate_init\": config[\"learning_rate_init\"],\n",
    "        \"max_iter\": config[\"max_iter\"],\n",
    "        \"best_threshold\": best_thresh,\n",
    "        # Default threshold = 0.5 metrics\n",
    "        \"train_acc_05\": train_default[\"accuracy\"],\n",
    "        \"train_rec_05\": train_default[\"recall\"],\n",
    "        \"train_prec_05\": train_default[\"precision\"],\n",
    "        \"train_auc_05\": train_default[\"auc\"],\n",
    "        \"val_acc_05\": val_default[\"accuracy\"],\n",
    "        \"val_rec_05\": val_default[\"recall\"],\n",
    "        \"val_prec_05\": val_default[\"precision\"],\n",
    "        \"val_auc_05\": val_default[\"auc\"],\n",
    "        \"test_acc_05\": test_default[\"accuracy\"],\n",
    "        \"test_rec_05\": test_default[\"recall\"],\n",
    "        \"test_prec_05\": test_default[\"precision\"],\n",
    "        \"test_auc_05\": test_default[\"auc\"],\n",
    "        # Tuned threshold metrics\n",
    "        \"val_acc_tuned\": val_tuned[\"accuracy\"],\n",
    "        \"val_rec_tuned\": val_tuned[\"recall\"],\n",
    "        \"val_prec_tuned\": val_tuned[\"precision\"],\n",
    "        \"val_auc_tuned\": val_tuned[\"auc\"],\n",
    "        \"test_acc_tuned\": test_tuned[\"accuracy\"],\n",
    "        \"test_rec_tuned\": test_tuned[\"recall\"],\n",
    "        \"test_prec_tuned\": test_tuned[\"precision\"],\n",
    "        \"test_auc_tuned\": test_tuned[\"auc\"],\n",
    "        # Confusion matrices at tuned threshold\n",
    "        \"val_tn\": tn_val,\n",
    "        \"val_fp\": fp_val,\n",
    "        \"val_fn\": fn_val,\n",
    "        \"val_tp\": tp_val,\n",
    "        \"test_tn\": tn_test,\n",
    "        \"test_fp\": fp_test,\n",
    "        \"test_fn\": fn_test,\n",
    "        \"test_tp\": tp_test,\n",
    "        # Meta\n",
    "        \"train_time\": train_time,\n",
    "        \"early_stop_epoch\": early_stop_epoch,\n",
    "        \"converged\": bool(converged),\n",
    "        \"constraint_met\": bool(constraint_met),\n",
    "        \"is_leader\": bool(is_leader),\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Result row builder defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search: 80 experiments\n",
      "============================================================\n",
      "[1/80] (128, 64, 32), α=1e-05, lr=0.001, max_iter=300 ... ❌ Acc=0.9091 Rec=0.9172 (1.6s)\n",
      "[2/80] (128, 64, 32), α=1e-05, lr=0.001, max_iter=500 ... ❌ Acc=0.9091 Rec=0.9172 (1.6s)\n",
      "[3/80] (128, 64, 32), α=1e-05, lr=0.0007, max_iter=300 ... ❌ Acc=0.9082 Rec=0.9190 (1.5s)\n",
      "[4/80] (128, 64, 32), α=1e-05, lr=0.0007, max_iter=500 ... ❌ Acc=0.9082 Rec=0.9190 (1.5s)\n",
      "[5/80] (128, 64, 32), α=0.0001, lr=0.001, max_iter=300 ... ⚠️ Acc=0.9016 Rec=0.9259 (1.1s)\n",
      "[6/80] (128, 64, 32), α=0.0001, lr=0.001, max_iter=500 ... ⚠️ Acc=0.9016 Rec=0.9259 (1.1s)\n",
      "[7/80] (128, 64, 32), α=0.0001, lr=0.0007, max_iter=300 ... ⚠️ Acc=0.9045 Rec=0.9293 (1.8s)\n",
      "[8/80] (128, 64, 32), α=0.0001, lr=0.0007, max_iter=500 ... ⚠️ Acc=0.9045 Rec=0.9293 (1.9s)\n",
      "[9/80] (128, 64, 32), α=0.001, lr=0.001, max_iter=300 ... ⚠️ Acc=0.9004 Rec=0.9310 (1.1s)\n",
      "[10/80] (128, 64, 32), α=0.001, lr=0.001, max_iter=500 ... ⚠️ Acc=0.9004 Rec=0.9310 (1.1s)\n",
      "[11/80] (128, 64, 32), α=0.001, lr=0.0007, max_iter=300 ... ❌ Acc=0.8983 Rec=0.9190 (1.2s)\n",
      "[12/80] (128, 64, 32), α=0.001, lr=0.0007, max_iter=500 ... ❌ Acc=0.8983 Rec=0.9190 (1.2s)\n",
      "[13/80] (128, 64, 32), α=0.01, lr=0.001, max_iter=300 ... ⚠️ Acc=0.9124 Rec=0.9414 (1.7s)\n",
      "[14/80] (128, 64, 32), α=0.01, lr=0.001, max_iter=500 ... ⚠️ Acc=0.9124 Rec=0.9414 (1.6s)\n",
      "[15/80] (128, 64, 32), α=0.01, lr=0.0007, max_iter=300 ... ⚠️ Acc=0.9086 Rec=0.9259 (1.8s)\n",
      "[16/80] (128, 64, 32), α=0.01, lr=0.0007, max_iter=500 ... ⚠️ Acc=0.9086 Rec=0.9259 (1.7s)\n",
      "[17/80] (256, 128, 64), α=1e-05, lr=0.001, max_iter=300 ... ⚠️ Acc=0.9103 Rec=0.9241 (2.1s)\n",
      "[18/80] (256, 128, 64), α=1e-05, lr=0.001, max_iter=500 ... ⚠️ Acc=0.9103 Rec=0.9241 (2.0s)\n",
      "[19/80] (256, 128, 64), α=1e-05, lr=0.0007, max_iter=300 ... ⚠️ Acc=0.9070 Rec=0.9414 (2.3s)\n",
      "[20/80] (256, 128, 64), α=1e-05, lr=0.0007, max_iter=500 ... ⚠️ Acc=0.9070 Rec=0.9414 (2.3s)\n",
      "[21/80] (256, 128, 64), α=0.0001, lr=0.001, max_iter=300 ... ⚠️ Acc=0.9033 Rec=0.9448 (2.3s)\n",
      "[22/80] (256, 128, 64), α=0.0001, lr=0.001, max_iter=500 ... ⚠️ Acc=0.9033 Rec=0.9448 (2.3s)\n",
      "[23/80] (256, 128, 64), α=0.0001, lr=0.0007, max_iter=300 ... ⚠️ Acc=0.9029 Rec=0.9345 (2.8s)\n",
      "[24/80] (256, 128, 64), α=0.0001, lr=0.0007, max_iter=500 ... ⚠️ Acc=0.9029 Rec=0.9345 (2.9s)\n",
      "[25/80] (256, 128, 64), α=0.001, lr=0.001, max_iter=300 ... ⚠️ Acc=0.9144 Rec=0.9534 (2.4s)\n",
      "[26/80] (256, 128, 64), α=0.001, lr=0.001, max_iter=500 ... ⚠️ Acc=0.9144 Rec=0.9534 (2.4s)\n",
      "[27/80] (256, 128, 64), α=0.001, lr=0.0007, max_iter=300 ... ⚠️ Acc=0.9107 Rec=0.9362 (2.4s)\n",
      "[28/80] (256, 128, 64), α=0.001, lr=0.0007, max_iter=500 ... ⚠️ Acc=0.9107 Rec=0.9362 (2.3s)\n",
      "[29/80] (256, 128, 64), α=0.01, lr=0.001, max_iter=300 ... ⚠️ Acc=0.9024 Rec=0.9431 (2.2s)\n",
      "[30/80] (256, 128, 64), α=0.01, lr=0.001, max_iter=500 ... ⚠️ Acc=0.9024 Rec=0.9431 (2.2s)\n",
      "[31/80] (256, 128, 64), α=0.01, lr=0.0007, max_iter=300 ... ⚠️ Acc=0.9078 Rec=0.9293 (2.3s)\n",
      "[32/80] (256, 128, 64), α=0.01, lr=0.0007, max_iter=500 ... ⚠️ Acc=0.9078 Rec=0.9293 (2.4s)\n",
      "[33/80] (256, 256, 128), α=1e-05, lr=0.001, max_iter=300 ... ❌ Acc=0.9037 Rec=0.9121 (3.0s)\n",
      "[34/80] (256, 256, 128), α=1e-05, lr=0.001, max_iter=500 ... ❌ Acc=0.9037 Rec=0.9121 (2.9s)\n",
      "[35/80] (256, 256, 128), α=1e-05, lr=0.0007, max_iter=300 ... ❌ Acc=0.9107 Rec=0.9052 (4.0s)\n",
      "[36/80] (256, 256, 128), α=1e-05, lr=0.0007, max_iter=500 ... ❌ Acc=0.9107 Rec=0.9052 (4.0s)\n",
      "[37/80] (256, 256, 128), α=0.0001, lr=0.001, max_iter=300 ... ❌ Acc=0.9107 Rec=0.9138 (6.0s)\n",
      "[38/80] (256, 256, 128), α=0.0001, lr=0.001, max_iter=500 ... ❌ Acc=0.9107 Rec=0.9138 (6.1s)\n",
      "[39/80] (256, 256, 128), α=0.0001, lr=0.0007, max_iter=300 ... ❌ Acc=0.9091 Rec=0.9086 (5.0s)\n",
      "[40/80] (256, 256, 128), α=0.0001, lr=0.0007, max_iter=500 ... ❌ Acc=0.9091 Rec=0.9086 (5.0s)\n",
      "[41/80] (256, 256, 128), α=0.001, lr=0.001, max_iter=300 ... ❌ Acc=0.9095 Rec=0.9069 (3.8s)\n",
      "[42/80] (256, 256, 128), α=0.001, lr=0.001, max_iter=500 ... ❌ Acc=0.9095 Rec=0.9069 (3.8s)\n",
      "[43/80] (256, 256, 128), α=0.001, lr=0.0007, max_iter=300 ... ❌ Acc=0.9095 Rec=0.9138 (3.5s)\n",
      "[44/80] (256, 256, 128), α=0.001, lr=0.0007, max_iter=500 ... ❌ Acc=0.9095 Rec=0.9138 (3.8s)\n",
      "[45/80] (256, 256, 128), α=0.01, lr=0.001, max_iter=300 ... ⚠️ Acc=0.9107 Rec=0.9207 (5.2s)\n",
      "[46/80] (256, 256, 128), α=0.01, lr=0.001, max_iter=500 ... ⚠️ Acc=0.9107 Rec=0.9207 (5.0s)\n",
      "[47/80] (256, 256, 128), α=0.01, lr=0.0007, max_iter=300 ... ⚠️ Acc=0.9103 Rec=0.9207 (7.3s)\n",
      "[48/80] (256, 256, 128), α=0.01, lr=0.0007, max_iter=500 ... ⚠️ Acc=0.9103 Rec=0.9207 (7.3s)\n",
      "[49/80] (128, 64), α=1e-05, lr=0.001, max_iter=300 ... ⚠️ Acc=0.9020 Rec=0.9241 (1.9s)\n",
      "[50/80] (128, 64), α=1e-05, lr=0.001, max_iter=500 ... ⚠️ Acc=0.9020 Rec=0.9241 (1.9s)\n",
      "[51/80] (128, 64), α=1e-05, lr=0.0007, max_iter=300 ... ⚠️ Acc=0.9078 Rec=0.9259 (2.4s)\n",
      "[52/80] (128, 64), α=1e-05, lr=0.0007, max_iter=500 ... ⚠️ Acc=0.9078 Rec=0.9259 (2.4s)\n",
      "[53/80] (128, 64), α=0.0001, lr=0.001, max_iter=300 ... ⚠️ Acc=0.9004 Rec=0.9362 (1.9s)\n",
      "[54/80] (128, 64), α=0.0001, lr=0.001, max_iter=500 ... ⚠️ Acc=0.9004 Rec=0.9362 (1.9s)\n",
      "[55/80] (128, 64), α=0.0001, lr=0.0007, max_iter=300 ... ⚠️ Acc=0.9070 Rec=0.9310 (2.7s)\n",
      "[56/80] (128, 64), α=0.0001, lr=0.0007, max_iter=500 ... ⚠️ Acc=0.9070 Rec=0.9310 (2.6s)\n",
      "[57/80] (128, 64), α=0.001, lr=0.001, max_iter=300 ... ❌ Acc=0.9074 Rec=0.9190 (1.8s)\n",
      "[58/80] (128, 64), α=0.001, lr=0.001, max_iter=500 ... ❌ Acc=0.9074 Rec=0.9190 (1.8s)\n",
      "[59/80] (128, 64), α=0.001, lr=0.0007, max_iter=300 ... ⚠️ Acc=0.8979 Rec=0.9224 (2.2s)\n",
      "[60/80] (128, 64), α=0.001, lr=0.0007, max_iter=500 ... ⚠️ Acc=0.8979 Rec=0.9224 (2.2s)\n",
      "[61/80] (128, 64), α=0.01, lr=0.001, max_iter=300 ... ❌ Acc=0.9033 Rec=0.9190 (2.2s)\n",
      "[62/80] (128, 64), α=0.01, lr=0.001, max_iter=500 ... ❌ Acc=0.9033 Rec=0.9190 (2.1s)\n",
      "[63/80] (128, 64), α=0.01, lr=0.0007, max_iter=300 ... ⚠️ Acc=0.8971 Rec=0.9259 (1.8s)\n",
      "[64/80] (128, 64), α=0.01, lr=0.0007, max_iter=500 ... ⚠️ Acc=0.8971 Rec=0.9259 (1.8s)\n",
      "[65/80] (64, 32), α=1e-05, lr=0.001, max_iter=300 ... ❌ Acc=0.8768 Rec=0.9017 (1.3s)\n",
      "[66/80] (64, 32), α=1e-05, lr=0.001, max_iter=500 ... ❌ Acc=0.8768 Rec=0.9017 (1.3s)\n",
      "[67/80] (64, 32), α=1e-05, lr=0.0007, max_iter=300 ... ❌ Acc=0.8532 Rec=0.8897 (1.3s)\n",
      "[68/80] (64, 32), α=1e-05, lr=0.0007, max_iter=500 ... ❌ Acc=0.8532 Rec=0.8897 (1.3s)\n",
      "[69/80] (64, 32), α=0.0001, lr=0.001, max_iter=300 ... ❌ Acc=0.8623 Rec=0.9017 (1.1s)\n",
      "[70/80] (64, 32), α=0.0001, lr=0.001, max_iter=500 ... ❌ Acc=0.8623 Rec=0.9017 (1.1s)\n",
      "[71/80] (64, 32), α=0.0001, lr=0.0007, max_iter=300 ... ❌ Acc=0.8268 Rec=0.9000 (1.1s)\n",
      "[72/80] (64, 32), α=0.0001, lr=0.0007, max_iter=500 ... ❌ Acc=0.8268 Rec=0.9000 (1.1s)\n",
      "[73/80] (64, 32), α=0.001, lr=0.001, max_iter=300 ... ❌ Acc=0.8946 Rec=0.8966 (1.6s)\n",
      "[74/80] (64, 32), α=0.001, lr=0.001, max_iter=500 ... ❌ Acc=0.8946 Rec=0.8966 (1.6s)\n",
      "[75/80] (64, 32), α=0.001, lr=0.0007, max_iter=300 ... ❌ Acc=0.8528 Rec=0.8966 (1.3s)\n",
      "[76/80] (64, 32), α=0.001, lr=0.0007, max_iter=500 ... ❌ Acc=0.8528 Rec=0.8966 (1.3s)\n",
      "[77/80] (64, 32), α=0.01, lr=0.001, max_iter=300 ... ❌ Acc=0.8710 Rec=0.8983 (1.3s)\n",
      "[78/80] (64, 32), α=0.01, lr=0.001, max_iter=500 ... ❌ Acc=0.8710 Rec=0.8983 (1.3s)\n",
      "[79/80] (64, 32), α=0.01, lr=0.0007, max_iter=300 ... ❌ Acc=0.8929 Rec=0.8948 (2.2s)\n",
      "[80/80] (64, 32), α=0.01, lr=0.0007, max_iter=500 ... ❌ Acc=0.8929 Rec=0.8948 (2.2s)\n",
      "============================================================\n",
      "Grid search complete in 201.3s\n",
      "Total experiments: 80\n",
      "Valid candidates (Recall >= 0.919): 42\n",
      "Leader candidates (beat baseline): 0\n",
      "Full results saved to: /Users/prajanv/CardioDetect/output/mlp_experiments/all_experiments.csv\n",
      "\n",
      "Top 10 valid candidates (tuned threshold):\n",
      "                            id hidden_layer_sizes  alpha  learning_rate_init  best_threshold  val_acc_tuned  val_rec_tuned  test_acc_tuned  test_rec_tuned  test_auc_tuned  is_leader\n",
      "mlp_exp_20251201_2105_model045    (256, 256, 128)  0.010              0.0010            0.37         0.9140         0.9241          0.9107          0.9207          0.9546      False\n",
      "mlp_exp_20251201_2105_model046    (256, 256, 128)  0.010              0.0010            0.37         0.9140         0.9241          0.9107          0.9207          0.9546      False\n",
      "mlp_exp_20251201_2105_model047    (256, 256, 128)  0.010              0.0007            0.37         0.9140         0.9207          0.9103          0.9207          0.9509      False\n",
      "mlp_exp_20251201_2105_model048    (256, 256, 128)  0.010              0.0007            0.37         0.9140         0.9207          0.9103          0.9207          0.9509      False\n",
      "mlp_exp_20251201_2105_model013      (128, 64, 32)  0.010              0.0010            0.30         0.9136         0.9345          0.9124          0.9414          0.9614      False\n",
      "mlp_exp_20251201_2105_model014      (128, 64, 32)  0.010              0.0010            0.30         0.9136         0.9345          0.9124          0.9414          0.9614      False\n",
      "mlp_exp_20251201_2105_model017     (256, 128, 64)  0.000              0.0010            0.33         0.9103         0.9241          0.9103          0.9241          0.9518      False\n",
      "mlp_exp_20251201_2105_model018     (256, 128, 64)  0.000              0.0010            0.33         0.9103         0.9241          0.9103          0.9241          0.9518      False\n",
      "mlp_exp_20251201_2105_model025     (256, 128, 64)  0.001              0.0010            0.34         0.9098         0.9310          0.9144          0.9534          0.9575      False\n",
      "mlp_exp_20251201_2105_model026     (256, 128, 64)  0.001              0.0010            0.34         0.9098         0.9310          0.9144          0.9534          0.9575      False\n"
     ]
    }
   ],
   "source": [
    "# ============ RUN FULL GRID SEARCH ============\n",
    "from itertools import product\n",
    "\n",
    "all_results = []\n",
    "experiment_count = 0\n",
    "start_time = datetime.now()\n",
    "\n",
    "print(f\"Starting grid search: {total_experiments} experiments\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for hidden, alpha, lr, max_iter in product(\n",
    "    HIDDEN_LAYER_SIZES, ALPHAS, LEARNING_RATES, MAX_ITERS\n",
    "):\n",
    "    experiment_count += 1\n",
    "\n",
    "    # Generate experiment ID\n",
    "    exp_id = f\"mlp_exp_{start_time.strftime('%Y%m%d_%H%M')}_model{experiment_count:03d}\"\n",
    "    config = {\n",
    "        \"hidden_layer_sizes\": hidden,\n",
    "        \"alpha\": alpha,\n",
    "        \"learning_rate_init\": lr,\n",
    "        \"max_iter\": max_iter,\n",
    "    }\n",
    "\n",
    "    # Progress\n",
    "    print(\n",
    "        f\"[{experiment_count}/{total_experiments}] {hidden}, α={alpha}, lr={lr}, max_iter={max_iter}\",\n",
    "        end=\" ... \",\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    t0 = time.time()\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden,\n",
    "        alpha=alpha,\n",
    "        learning_rate_init=lr,\n",
    "        max_iter=max_iter,\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        batch_size=\"auto\",\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\")\n",
    "        mlp.fit(X_train_s, y_train)\n",
    "        converged = not any(\"ConvergenceWarning\" in str(warning.category) for warning in w)\n",
    "\n",
    "    train_time = time.time() - t0\n",
    "    early_stop_epoch = mlp.n_iter_ if hasattr(mlp, \"n_iter_\") else \"N/A\"\n",
    "\n",
    "    # Evaluate at default threshold 0.5\n",
    "    train_default = eval_model_at_threshold(mlp, X_train_s, y_train, 0.5)\n",
    "    val_default = eval_model_at_threshold(mlp, X_val_s, y_val, 0.5)\n",
    "    test_default = eval_model_at_threshold(mlp, X_test_s, y_test, 0.5)\n",
    "\n",
    "    # Threshold tuning\n",
    "    best_thresh, val_tuned = find_best_threshold(\n",
    "        mlp, X_val_s, y_val, RECALL_CONSTRAINT\n",
    "    )\n",
    "\n",
    "    # Validation metrics & confusion at tuned threshold\n",
    "    y_proba_val = mlp.predict_proba(X_val_s)[:, 1]\n",
    "    y_pred_val_tuned = (y_proba_val >= best_thresh).astype(int)\n",
    "    val_cm = confusion_matrix(y_val, y_pred_val_tuned)\n",
    "\n",
    "    # Test metrics & confusion at tuned threshold\n",
    "    y_proba_test = mlp.predict_proba(X_test_s)[:, 1]\n",
    "    y_pred_test_tuned = (y_proba_test >= best_thresh).astype(int)\n",
    "    test_tuned = compute_metrics(y_test, y_pred_test_tuned, y_proba_test)\n",
    "    test_cm = confusion_matrix(y_test, y_pred_test_tuned)\n",
    "\n",
    "    # Build result row and collect\n",
    "    row = build_result_row(\n",
    "        exp_id,\n",
    "        config,\n",
    "        train_default,\n",
    "        val_default,\n",
    "        test_default,\n",
    "        best_thresh,\n",
    "        val_tuned,\n",
    "        test_tuned,\n",
    "        val_cm,\n",
    "        test_cm,\n",
    "        train_time,\n",
    "        early_stop_epoch,\n",
    "        converged,\n",
    "    )\n",
    "    all_results.append(row)\n",
    "\n",
    "    status = \"✅\" if row[\"is_leader\"] else (\"⚠️\" if row[\"constraint_met\"] else \"❌\")\n",
    "    print(\n",
    "        f\"{status} Acc={row['test_acc_tuned']:.4f} Rec={row['test_rec_tuned']:.4f} ({train_time:.1f}s)\"\n",
    "    )\n",
    "\n",
    "# Build DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "total_time = (datetime.now() - start_time).total_seconds()\n",
    "print(\"=\" * 60)\n",
    "print(f\"Grid search complete in {total_time:.1f}s\")\n",
    "print(f\"Total experiments: {len(results_df)}\")\n",
    "print(\n",
    "    f\"Valid candidates (Recall >= {RECALL_CONSTRAINT}): {int(results_df['constraint_met'].sum())}\"\n",
    ")\n",
    "print(\n",
    "    f\"Leader candidates (beat baseline): {int(results_df['is_leader'].sum())}\"\n",
    ")\n",
    "\n",
    "# Save full results as CSV\n",
    "csv_path = RESULTS_DIR / \"all_experiments.csv\"\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"Full results saved to: {csv_path}\")\n",
    "\n",
    "# Show top 10 valid candidates (by tuned metrics)\n",
    "valid_df = results_df[results_df[\"constraint_met\"]].copy()\n",
    "if not valid_df.empty:\n",
    "    valid_df = valid_df.sort_values(\n",
    "        by=[\"val_acc_tuned\", \"test_acc_tuned\", \"test_auc_tuned\"],\n",
    "        ascending=[False, False, False],\n",
    "    )\n",
    "\n",
    "    top_10 = valid_df.head(10)[\n",
    "        [\n",
    "            \"id\",\n",
    "            \"hidden_layer_sizes\",\n",
    "            \"alpha\",\n",
    "            \"learning_rate_init\",\n",
    "            \"best_threshold\",\n",
    "            \"val_acc_tuned\",\n",
    "            \"val_rec_tuned\",\n",
    "            \"test_acc_tuned\",\n",
    "            \"test_rec_tuned\",\n",
    "            \"test_auc_tuned\",\n",
    "            \"is_leader\",\n",
    "        ]\n",
    "    ]\n",
    "    print(\"\\nTop 10 valid candidates (tuned threshold):\")\n",
    "    print(top_10.round(4).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo valid candidates found that meet the recall constraint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obsidian leaderboard generation has been moved to a separate script:\n",
    "# `scripts/generate_mlp_obsidian_notes.py`\n",
    "# This cell is intentionally left empty.\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsidian markdown generation is now handled by `scripts/generate_mlp_obsidian_notes.py`.\n",
    "# Nothing to do in this cell.\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final analysis and recommendation can be performed using the\n",
    "# leaderboard generated by the Obsidian script.\n",
    "# See: obsidian_notes/experiments_mlp/summaries/mlp_leaderboard.md\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold tuning notes and CSV export are now produced directly\n",
    "# from the results CSV by `scripts/generate_mlp_obsidian_notes.py`.\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b576f1c5",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Open Obsidian** and point it at `CardioDetect/obsidian_notes/`\n",
    "2. **Review the leaderboard** at `experiments_mlp/summaries/mlp_leaderboard.md`\n",
    "3. **If a candidate beats baseline**:\n",
    "   - Open its experiment note for full details\n",
    "   - Update `00_complete_project_walkthrough.ipynb` with the new best model\n",
    "   - Save the model to `models/` with a new name\n",
    "4. **If no candidate beats baseline**:\n",
    "   - Keep `mlp_v2_best` as the production model\n",
    "   - Document findings in `MY_NOTES.md`\n",
    "\n",
    "---\n",
    "\n",
    "**Grid Search Summary**:\n",
    "- 80 configurations tested (5 architectures × 4 alphas × 2 LRs × 2 max_iters)\n",
    "- Threshold tuning applied to each with recall constraint ≥ 0.9190\n",
    "- Results ranked by validation accuracy, then test accuracy, then AUC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
